# API Documentation

## Core Functions

### `findEncodings(images)`

Extracts face encodings from a list of images.

**Parameters:**
- `images` (list): List of image arrays loaded by cv2.imread()

**Returns:**
- `encodeList` (list): List of 128-dimensional face encodings

**Usage:**
```python
images = [img1, img2, img3]
encodings = findEncodings(images)
# Returns: [encoding1, encoding2, encoding3]
```

**Process:**
1. Converts each image from BGR to RGB
2. Detects face locations using HOG algorithm
3. Generates 128-D encoding for each face
4. Skips images with no detectable faces

**Example:**
```python
import cv2

# Load images
img1 = cv2.imread('person1.jpg')
img2 = cv2.imread('person2.jpg')

# Get encodings
encodings = findEncodings([img1, img2])
print(f"Generated {len(encodings)} encodings")
```

---

### `markAttendence(name)`

Records attendance for a recognized person.

**Parameters:**
- `name` (str): Name of the person to mark attendance for

**Returns:**
- None (writes to CSV file)

**Side Effects:**
- Creates or appends to `attendance.csv`
- Prints status message to console

**Usage:**
```python
markAttendence("JOHN_DOE")
# Output: ✓ Attendance marked for JOHN_DOE on 2026-01-28 at 14:30:15
```

**CSV Format:**
| Name | Date | Time |
|------|------|------|
| JOHN_DOE | 2026-01-28 | 14:30:15 |

**Duplicate Prevention:**
- Checks if person already marked for current date
- Prevents multiple entries per day

**Example:**
```python
# First call
markAttendence("JANE_SMITH")
# ✓ Attendance marked for JANE_SMITH on 2026-01-28 at 14:30:15

# Second call (same day)
markAttendence("JANE_SMITH")
# ℹ Attendance already marked for JANE_SMITH today.
```

---

### `run_attendance_system()`

Main function that runs the webcam-based attendance system.

**Parameters:**
- None

**Returns:**
- None

**Side Effects:**
- Opens webcam window
- Displays live video with face detection
- Calls `markAttendence()` when faces recognized
- Creates/updates `attendance.csv`

**Usage:**
```python
run_attendance_system()
# Press 'q' to quit
```

**Controls:**
- `q` - Quit the system

**Process:**
1. Opens default webcam (index 0)
2. Captures frames continuously
3. Detects faces in each frame
4. Compares with known encodings
5. Draws bounding boxes and labels
6. Marks attendance for recognized faces
7. Displays processed frame

**Visual Feedback:**
- Green box + Name = Recognized person
- Red box + "Unknown" = Unrecognized person

---

## Data Structures

### Face Encoding

**Type:** numpy.ndarray  
**Shape:** (128,)  
**Data Type:** float64

**Description:**
A 128-dimensional vector representing unique facial features. Generated by deep learning model trained on millions of faces.

**Properties:**
- Invariant to lighting changes (within reason)
- Invariant to small pose variations
- Consistent across similar images of same person

**Comparison:**
```python
import face_recognition
import numpy as np

# Compare two encodings
distance = face_recognition.face_distance([encoding1], encoding2)
match = distance < 0.6  # True if match

# Using built-in comparison
matches = face_recognition.compare_faces([encoding1], encoding2)
# Returns: [True] or [False]
```

---

### Image Arrays

**Type:** numpy.ndarray  
**Shape:** (height, width, 3)  
**Data Type:** uint8  
**Color Space:** BGR (OpenCV default)

**Loading:**
```python
img = cv2.imread('photo.jpg')
# Shape: (480, 640, 3) for 640x480 image
```

**Conversion for face_recognition:**
```python
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
```

---

### Face Locations

**Type:** list of tuples  
**Format:** [(top, right, bottom, left), ...]

**Example:**
```python
face_locations = face_recognition.face_locations(img)
# Returns: [(142, 617, 409, 349)]
# Meaning: top=142, right=617, bottom=409, left=349
```

**Drawing Rectangle:**
```python
for (top, right, bottom, left) in face_locations:
    cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 2)
```

---

## Configuration Variables

### `dataset_path`

**Type:** str  
**Default:** `'/home/claude/test_dataset'`

**Description:** Path to directory containing person folders with training images.

**Structure:**
```
dataset_path/
├── Person1/
│   └── photo.jpg
└── Person2/
    └── photo.jpg
```

---

### Confidence Threshold

**Variable:** Within comparison logic  
**Default:** `0.6`

**Description:** Maximum face distance for considering a match.

**Range:** 0.0 - 1.0
- Lower = stricter matching
- Higher = more lenient matching

**Tuning:**
```python
# In run_attendance_system() function
if matches[matchIndex] and faceDis[matchIndex] < 0.6:  # Adjust here
```

---

### Frame Resize Factor

**Variable:** In `cv2.resize()` call  
**Default:** `0.25` (1/4 size)

**Description:** Scaling factor for processing frames.

**Impact:**
- Smaller = faster processing, lower accuracy
- Larger = slower processing, higher accuracy

**Adjustment:**
```python
imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)  # Change both 0.25 values
```

---

## Error Handling

### Image Loading Errors

```python
current_img = cv2.imread(full_file_path)
if current_img is None:
    print(f"Warning: Failed to load image at {full_file_path}. Skipping.")
    continue
```

### Face Detection Errors

```python
face_locations = face_recognition.face_locations(img_rgb)
if face_locations:
    encode = face_recognition.face_encodings(img_rgb, face_locations)[0]
else:
    print(f"Warning: No face found in image. Skipping.")
```

### Webcam Errors

```python
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Could not open video stream.")
    return
```

### Frame Capture Errors

```python
success, img = cap.read()
if not success:
    print("Failed to grab frame")
    break
```

---

## Performance Optimization

### 1. Frame Resizing

```python
# Resize to 1/4 size for 16x speedup
imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)
```

### 2. Skip Frames

```python
# Process every Nth frame
frame_count = 0
if frame_count % 3 == 0:  # Process every 3rd frame
    # Face detection logic
frame_count += 1
```

### 3. Limit Dataset Size

- Keep dataset under 100 people for real-time performance
- More people = slower comparison

### 4. Use GPU Acceleration (Advanced)

```python
# Install: pip install face_recognition[gpu]
# Requires CUDA-capable GPU
```

---

## Integration Examples

### Database Integration

```python
import sqlite3

def markAttendence_db(name):
    conn = sqlite3.connect('attendance.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS attendance
        (id INTEGER PRIMARY KEY, name TEXT, date TEXT, time TEXT)
    ''')
    
    now = datetime.now()
    date = now.strftime('%Y-%m-%d')
    time = now.strftime('%H:%M:%S')
    
    cursor.execute(
        'SELECT * FROM attendance WHERE name=? AND date=?',
        (name, date)
    )
    
    if not cursor.fetchone():
        cursor.execute(
            'INSERT INTO attendance (name, date, time) VALUES (?, ?, ?)',
            (name, date, time)
        )
        conn.commit()
        print(f"✓ Attendance marked for {name}")
    
    conn.close()
```

### Email Notification

```python
import smtplib
from email.mime.text import MIMEText

def send_attendance_email(name):
    msg = MIMEText(f"Attendance marked for {name}")
    msg['Subject'] = 'Attendance Notification'
    msg['From'] = 'system@example.com'
    msg['To'] = 'admin@example.com'
    
    with smtplib.SMTP('smtp.gmail.com', 587) as server:
        server.starttls()
        server.login('user@gmail.com', 'password')
        server.send_message(msg)
```

### REST API Endpoint

```python
from flask import Flask, jsonify
import pandas as pd

app = Flask(__name__)

@app.route('/attendance/<date>')
def get_attendance(date):
    df = pd.read_csv('attendance.csv')
    records = df[df['Date'] == date].to_dict('records')
    return jsonify(records)

if __name__ == '__main__':
    app.run(port=5000)
```

---

## Constants & Defaults

| Constant | Value | Purpose |
|----------|-------|---------|
| CSV_FILE | 'attendance.csv' | Output filename |
| CONFIDENCE_THRESHOLD | 0.6 | Face match threshold |
| RESIZE_FACTOR | 0.25 | Frame processing scale |
| WEBCAM_INDEX | 0 | Default camera |
| DATE_FORMAT | '%Y-%m-%d' | Date string format |
| TIME_FORMAT | '%H:%M:%S' | Time string format |
| BOX_COLOR_KNOWN | (0, 255, 0) | Green for known |
| BOX_COLOR_UNKNOWN | (0, 0, 255) | Red for unknown |

---

**For more details, see the source code in `attendance_system.py`**
